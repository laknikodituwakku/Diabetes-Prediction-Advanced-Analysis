{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5d7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import Neccessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Import Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Import Model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "# Set the decimal format\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "#%pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c90361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:/Lakni UOC/4th Year/1st sem/ST 4052 - Statistical Learning II/2.grp project 1/codes_diabetes/diabetes_prediction_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49058788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589bd467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without duplicates:(96146, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>smoking_history_current</th>\n",
       "      <th>smoking_history_no info</th>\n",
       "      <th>smoking_history_non-smoker</th>\n",
       "      <th>smoking_history_past_smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.60</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.70</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.00</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.80</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease   bmi  HbA1c_level  \\\n",
       "0       0 80.00             0              1 25.19         6.60   \n",
       "1       0 54.00             0              0 27.32         6.60   \n",
       "2       1 28.00             0              0 27.32         5.70   \n",
       "3       0 36.00             0              0 23.45         5.00   \n",
       "4       1 76.00             1              1 20.14         4.80   \n",
       "\n",
       "   blood_glucose_level  diabetes  smoking_history_current  \\\n",
       "0                  140         0                        0   \n",
       "1                   80         0                        0   \n",
       "2                  158         0                        0   \n",
       "3                  155         0                        1   \n",
       "4                  155         0                        1   \n",
       "\n",
       "   smoking_history_no info  smoking_history_non-smoker  \\\n",
       "0                        0                           1   \n",
       "1                        1                           0   \n",
       "2                        0                           1   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   smoking_history_past_smoker  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.drop_duplicates(inplace=True)\n",
    "print(f'without duplicates:{df_copy.shape}')\n",
    "\n",
    "# Remove Unneccessary value [0.02%]\n",
    "df2 = df_copy[df_copy['gender'] != 'Other']\n",
    "\n",
    "# Define a function to map the existing categories to new ones\n",
    "def recategorize_smoking(smoking_status):\n",
    "    if smoking_status == 'never':\n",
    "        return 'non-smoker'\n",
    "    elif smoking_status == 'current':\n",
    "        return 'current'\n",
    "    elif smoking_status in ['ever', 'former', 'not current']:\n",
    "        return 'past_smoker'\n",
    "    else:\n",
    "        return 'no info'\n",
    "    \n",
    "# Apply the function to the 'smoking_history' column\n",
    "df2['smoking_history'] = df2['smoking_history'].apply(recategorize_smoking)\n",
    "\n",
    "#encoding\n",
    "gender = {'Female':0,'Male':1}\n",
    "df2['gender'] =df2['gender'].replace(gender)\n",
    "\n",
    "def perform_one_hot_encoding(df2, column_name):\n",
    "    # Perform one-hot encoding on the specified column\n",
    "    dummies = pd.get_dummies(df2[column_name], prefix=column_name)\n",
    "\n",
    "    # Drop the original column and append the new dummy columns to the dataframe\n",
    "    df2 = pd.concat([df2.drop(column_name, axis=1), dummies], axis=1)\n",
    "\n",
    "    return df2\n",
    "\n",
    "# Perform one-hot encoding on the smoking history variable\n",
    "data = perform_one_hot_encoding(df2, 'smoking_history')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c64d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96128 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   gender                       96128 non-null  int64  \n",
      " 1   age                          96128 non-null  float64\n",
      " 2   hypertension                 96128 non-null  int64  \n",
      " 3   heart_disease                96128 non-null  int64  \n",
      " 4   bmi                          96128 non-null  float64\n",
      " 5   HbA1c_level                  96128 non-null  float64\n",
      " 6   blood_glucose_level          96128 non-null  int64  \n",
      " 7   diabetes                     96128 non-null  int64  \n",
      " 8   smoking_history_current      96128 non-null  uint8  \n",
      " 9   smoking_history_no info      96128 non-null  uint8  \n",
      " 10  smoking_history_non-smoker   96128 non-null  uint8  \n",
      " 11  smoking_history_past_smoker  96128 non-null  uint8  \n",
      "dtypes: float64(3), int64(5), uint8(4)\n",
      "memory usage: 7.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c09f74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96128 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count  Dtype   \n",
      "---  ------                       --------------  -----   \n",
      " 0   gender                       96128 non-null  category\n",
      " 1   age                          96128 non-null  float64 \n",
      " 2   hypertension                 96128 non-null  category\n",
      " 3   heart_disease                96128 non-null  category\n",
      " 4   bmi                          96128 non-null  float64 \n",
      " 5   HbA1c_level                  96128 non-null  float64 \n",
      " 6   blood_glucose_level          96128 non-null  int64   \n",
      " 7   diabetes                     96128 non-null  category\n",
      " 8   smoking_history_current      96128 non-null  category\n",
      " 9   smoking_history_no info      96128 non-null  category\n",
      " 10  smoking_history_non-smoker   96128 non-null  category\n",
      " 11  smoking_history_past_smoker  96128 non-null  category\n",
      "dtypes: category(8), float64(3), int64(1)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "int_cols = ['gender','hypertension','heart_disease','diabetes','smoking_history_current','smoking_history_no info','smoking_history_non-smoker','smoking_history_past_smoker']\n",
    "\n",
    "for col in int_cols:\n",
    "    data[col] = data[col].astype('category')\n",
    "    \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd6dcf",
   "metadata": {},
   "source": [
    "## split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93604396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_current</th>\n",
       "      <th>smoking_history_non-smoker</th>\n",
       "      <th>smoking_history_past_smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.60</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.70</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.00</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.80</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender   age hypertension heart_disease   bmi  HbA1c_level  \\\n",
       "0      0 80.00            0             1 25.19         6.60   \n",
       "1      0 54.00            0             0 27.32         6.60   \n",
       "2      1 28.00            0             0 27.32         5.70   \n",
       "3      0 36.00            0             0 23.45         5.00   \n",
       "4      1 76.00            1             1 20.14         4.80   \n",
       "\n",
       "   blood_glucose_level smoking_history_current smoking_history_non-smoker  \\\n",
       "0                  140                       0                          1   \n",
       "1                   80                       0                          0   \n",
       "2                  158                       0                          1   \n",
       "3                  155                       1                          0   \n",
       "4                  155                       1                          0   \n",
       "\n",
       "  smoking_history_past_smoker  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(['diabetes',\"smoking_history_no info\"],axis=1)\n",
    "y = data[\"diabetes\"]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8b44c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_current</th>\n",
       "      <th>smoking_history_non-smoker</th>\n",
       "      <th>smoking_history_past_smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39756</th>\n",
       "      <td>0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>3.50</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75304</th>\n",
       "      <td>1</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.49</td>\n",
       "      <td>8.80</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19765</th>\n",
       "      <td>1</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.69</td>\n",
       "      <td>4.80</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97291</th>\n",
       "      <td>1</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37660</th>\n",
       "      <td>0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.95</td>\n",
       "      <td>5.70</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age hypertension heart_disease   bmi  HbA1c_level  \\\n",
       "39756      0  8.00            0             0 15.90         3.50   \n",
       "75304      1 65.00            1             1 28.49         8.80   \n",
       "19765      1 64.00            1             0 33.69         4.80   \n",
       "97291      1 49.00            0             0 21.84         5.00   \n",
       "37660      0 26.00            0             0 21.95         5.70   \n",
       "\n",
       "       blood_glucose_level smoking_history_current smoking_history_non-smoker  \\\n",
       "39756                   90                       0                          0   \n",
       "75304                  145                       0                          1   \n",
       "19765                   80                       0                          0   \n",
       "97291                  130                       0                          1   \n",
       "37660                  158                       0                          1   \n",
       "\n",
       "      smoking_history_past_smoker  \n",
       "39756                           0  \n",
       "75304                           0  \n",
       "19765                           0  \n",
       "97291                           0  \n",
       "37660                           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature, test_feature, train_label, test_label = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "train_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8d3528",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Logistic\n",
      "=================\n",
      "Training Accuracy: 0.9593\n",
      "Training Error Rate: 0.0407\n",
      "Training F1 Score: 0.9564\n",
      "Training Confusion Matrix:\n",
      "[[69487   634]\n",
      " [ 2493  4288]]\n",
      "Training sensitivity:  0.6323551098658015\n",
      "Training specificity:  0.9909584860455498\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9573\n",
      "Test Error Rate: 0.0427\n",
      "Test F1 Score: 0.9541\n",
      "Test Confusion Matrix:\n",
      "[[17355   170]\n",
      " [  650  1051]]\n",
      "Test sensitivity:  0.6178718400940623\n",
      "Test specificity:  0.9902995720399429\n",
      "\n",
      "\n",
      "\n",
      "Ridge\n",
      "=====\n",
      "Training Accuracy: 0.9528\n",
      "Training Error Rate: 0.0472\n",
      "Training F1 Score: 0.9487\n",
      "Training Confusion Matrix:\n",
      "[[69365   756]\n",
      " [ 2877  3904]]\n",
      "Training sensitivity:  0.5757262940569238\n",
      "Training specificity:  0.989218636357154\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9511\n",
      "Test Error Rate: 0.0489\n",
      "Test F1 Score: 0.9467\n",
      "Test Confusion Matrix:\n",
      "[[17329   196]\n",
      " [  745   956]]\n",
      "Test sensitivity:  0.5620223398001176\n",
      "Test specificity:  0.9888159771754637\n",
      "\n",
      "\n",
      "\n",
      "Lasso\n",
      "=====\n",
      "Training Accuracy: 0.9593\n",
      "Training Error Rate: 0.0407\n",
      "Training F1 Score: 0.9563\n",
      "Training Confusion Matrix:\n",
      "[[69475   646]\n",
      " [ 2486  4295]]\n",
      "Training sensitivity:  0.6333874059873175\n",
      "Training specificity:  0.9907873532893142\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9571\n",
      "Test Error Rate: 0.0429\n",
      "Test F1 Score: 0.9539\n",
      "Test Confusion Matrix:\n",
      "[[17351   174]\n",
      " [  650  1051]]\n",
      "Test sensitivity:  0.6178718400940623\n",
      "Test specificity:  0.9900713266761769\n",
      "\n",
      "\n",
      "\n",
      "Elastic-net\n",
      "===========\n",
      "Training Accuracy: 0.9427\n",
      "Training Error Rate: 0.0573\n",
      "Training F1 Score: 0.9332\n",
      "Training Confusion Matrix:\n",
      "[[69691   430]\n",
      " [ 3979  2802]]\n",
      "Training sensitivity:  0.41321339035540483\n",
      "Training specificity:  0.9938677429015559\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9409\n",
      "Test Error Rate: 0.0591\n",
      "Test F1 Score: 0.9308\n",
      "Test Confusion Matrix:\n",
      "[[17414   111]\n",
      " [ 1025   676]]\n",
      "Test sensitivity:  0.3974132863021752\n",
      "Test specificity:  0.9936661911554922\n",
      "\n",
      "\n",
      "\n",
      "Random Forest\n",
      "=============\n",
      "Training Accuracy: 0.9992\n",
      "Training Error Rate: 0.0008\n",
      "Training F1 Score: 0.9992\n",
      "Training Confusion Matrix:\n",
      "[[70116     5]\n",
      " [   60  6721]]\n",
      "Training sensitivity:  0.9911517475298629\n",
      "Training specificity:  0.9999286946849019\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9667\n",
      "Test Error Rate: 0.0333\n",
      "Test F1 Score: 0.9642\n",
      "Test Confusion Matrix:\n",
      "[[17445    80]\n",
      " [  560  1141]]\n",
      "Test sensitivity:  0.6707818930041153\n",
      "Test specificity:  0.995435092724679\n",
      "\n",
      "\n",
      "\n",
      "GausianNB\n",
      "=========\n",
      "Training Accuracy: 0.8859\n",
      "Training Error Rate: 0.1141\n",
      "Training F1 Score: 0.8954\n",
      "Training Confusion Matrix:\n",
      "[[64154  5967]\n",
      " [ 2808  3973]]\n",
      "Training sensitivity:  0.5859017843975814\n",
      "Training specificity:  0.9149042369618231\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8817\n",
      "Test Error Rate: 0.1183\n",
      "Test F1 Score: 0.8920\n",
      "Test Confusion Matrix:\n",
      "[[15963  1562]\n",
      " [  713   988]]\n",
      "Test sensitivity:  0.5808348030570253\n",
      "Test specificity:  0.910870185449358\n",
      "\n",
      "\n",
      "\n",
      "XGBoost\n",
      "=======\n",
      "Training Accuracy: 0.9761\n",
      "Training Error Rate: 0.0239\n",
      "Training F1 Score: 0.9745\n",
      "Training Confusion Matrix:\n",
      "[[70088    33]\n",
      " [ 1804  4977]]\n",
      "Training sensitivity:  0.7339625423978764\n",
      "Training specificity:  0.9995293849203519\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9687\n",
      "Test Error Rate: 0.0313\n",
      "Test F1 Score: 0.9663\n",
      "Test Confusion Matrix:\n",
      "[[17472    53]\n",
      " [  548  1153]]\n",
      "Test sensitivity:  0.6778365667254557\n",
      "Test specificity:  0.9969757489300999\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define your categorical and numeric columns\n",
    "categorical_cols = ['gender', 'hypertension', 'heart_disease', 'smoking_history_current', 'smoking_history_non-smoker', 'smoking_history_past_smoker']\n",
    "numeric_cols = ['age', 'blood_glucose_level','HbA1c_level', 'bmi']\n",
    "\n",
    "# ... (load your train and test data)\n",
    "\n",
    "models = {\n",
    "    'Multiple Logistic': LogisticRegression(solver='liblinear'),\n",
    "    'Ridge': LogisticRegression(penalty='l2', C=1.0),\n",
    "    'Lasso': LogisticRegression(penalty='l1', C=1, solver='liblinear'),\n",
    "    'Elastic-net':LogisticRegression(penalty='elasticnet', l1_ratio=0.5, C=1, solver='saga'),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'GausianNB': GaussianNB(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "# Create an OneHotEncoder instance\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Fit and transform the encoder on your categorical columns\n",
    "train_cat_encoded = encoder.fit_transform(train_feature[categorical_cols])\n",
    "test_cat_encoded = encoder.transform(test_feature[categorical_cols])\n",
    "\n",
    "# Concatenate the encoded categorical features with the numeric features\n",
    "train_encoded = np.concatenate((train_cat_encoded, train_feature[numeric_cols]), axis=1)\n",
    "test_encoded = np.concatenate((test_cat_encoded, test_feature[numeric_cols]), axis=1)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    print('=' * len(name))\n",
    "\n",
    "    # Fit the model on the encoded data\n",
    "    model.fit(train_encoded, train_label)\n",
    "    \n",
    "     # Training set\n",
    "    train_pred = model.predict(train_encoded)\n",
    "    train_acc = accuracy_score(train_label, train_pred)\n",
    "    train_err = 1 - train_acc\n",
    "    train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "    train_cm = confusion_matrix(train_label, train_pred)\n",
    "    train_sensitivity = train_cm[1, 1] / (train_cm[1, 1] + train_cm[1, 0])\n",
    "    train_specificity = train_cm[0, 0] / (train_cm[0, 0] + train_cm[0, 1])\n",
    "\n",
    "    \n",
    "    # Test set\n",
    "    test_pred = model.predict(test_encoded)\n",
    "    test_acc = accuracy_score(test_label, test_pred)\n",
    "    test_err = 1 - test_acc\n",
    "    test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "    test_cm = confusion_matrix(test_label, test_pred)\n",
    "    test_sensitivity = test_cm[1, 1] / (test_cm[1, 1] + test_cm[1, 0])\n",
    "    test_specificity = test_cm[0, 0] / (test_cm[0, 0] + test_cm[0, 1])\n",
    "\n",
    "\n",
    "    print(f'Training Accuracy: {train_acc:.4f}')\n",
    "    print(f'Training Error Rate: {train_err:.4f}')\n",
    "    print(f'Training F1 Score: {train_f1:.4f}')\n",
    "    print(f'Training Confusion Matrix:\\n{train_cm}')\n",
    "    print(\"Training sensitivity: \", train_sensitivity)\n",
    "    print(\"Training specificity: \", train_specificity)\n",
    "    print('\\n')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test Error Rate: {test_err:.4f}')\n",
    "    print(f'Test F1 Score: {test_f1:.4f}')\n",
    "    print(f'Test Confusion Matrix:\\n{test_cm}')\n",
    "    print(\"Test sensitivity: \", test_sensitivity)\n",
    "    print(\"Test specificity: \", test_specificity)\n",
    "\n",
    "    print('\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c845d294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Logistic\n",
      "=================\n",
      "Training Accuracy: 0.9593\n",
      "Training Error Rate: 0.0407\n",
      "Training F1 Score: 0.9564\n",
      "Training Confusion Matrix:\n",
      "[[69487   634]\n",
      " [ 2493  4288]]\n",
      "Training sensitivity:  0.6323551098658015\n",
      "Training specificity:  0.9909584860455498\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9573\n",
      "Test Error Rate: 0.0427\n",
      "Test F1 Score: 0.9541\n",
      "Test Confusion Matrix:\n",
      "[[17355   170]\n",
      " [  650  1051]]\n",
      "Test sensitivity:  0.6178718400940623\n",
      "Test specificity:  0.9902995720399429\n",
      "\n",
      "\n",
      "\n",
      "Ridge\n",
      "=====\n",
      "Training Accuracy: 0.9528\n",
      "Training Error Rate: 0.0472\n",
      "Training F1 Score: 0.9487\n",
      "Training Confusion Matrix:\n",
      "[[69365   756]\n",
      " [ 2877  3904]]\n",
      "Training sensitivity:  0.5757262940569238\n",
      "Training specificity:  0.989218636357154\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9511\n",
      "Test Error Rate: 0.0489\n",
      "Test F1 Score: 0.9467\n",
      "Test Confusion Matrix:\n",
      "[[17329   196]\n",
      " [  745   956]]\n",
      "Test sensitivity:  0.5620223398001176\n",
      "Test specificity:  0.9888159771754637\n",
      "\n",
      "\n",
      "\n",
      "Lasso\n",
      "=====\n",
      "Training Accuracy: 0.9593\n",
      "Training Error Rate: 0.0407\n",
      "Training F1 Score: 0.9564\n",
      "Training Confusion Matrix:\n",
      "[[69479   642]\n",
      " [ 2487  4294]]\n",
      "Training sensitivity:  0.6332399351128152\n",
      "Training specificity:  0.9908443975413928\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9571\n",
      "Test Error Rate: 0.0429\n",
      "Test F1 Score: 0.9539\n",
      "Test Confusion Matrix:\n",
      "[[17351   174]\n",
      " [  650  1051]]\n",
      "Test sensitivity:  0.6178718400940623\n",
      "Test specificity:  0.9900713266761769\n",
      "\n",
      "\n",
      "\n",
      "Elastic-net\n",
      "===========\n",
      "Training Accuracy: 0.9426\n",
      "Training Error Rate: 0.0574\n",
      "Training F1 Score: 0.9330\n",
      "Training Confusion Matrix:\n",
      "[[69699   422]\n",
      " [ 3993  2788]]\n",
      "Training sensitivity:  0.4111487981123728\n",
      "Training specificity:  0.993981831405713\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9410\n",
      "Test Error Rate: 0.0590\n",
      "Test F1 Score: 0.9308\n",
      "Test Confusion Matrix:\n",
      "[[17417   108]\n",
      " [ 1027   674]]\n",
      "Test sensitivity:  0.39623750734861846\n",
      "Test specificity:  0.9938373751783167\n",
      "\n",
      "\n",
      "\n",
      "Random Forest\n",
      "=============\n",
      "Training Accuracy: 0.9761\n",
      "Training Error Rate: 0.0239\n",
      "Training F1 Score: 0.9744\n",
      "Training Confusion Matrix:\n",
      "[[70111    10]\n",
      " [ 1830  4951]]\n",
      "Training sensitivity:  0.7301282996608169\n",
      "Training specificity:  0.9998573893698036\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9692\n",
      "Test Error Rate: 0.0308\n",
      "Test F1 Score: 0.9665\n",
      "Test Confusion Matrix:\n",
      "[[17504    21]\n",
      " [  571  1130]]\n",
      "Test sensitivity:  0.6643151087595532\n",
      "Test specificity:  0.9988017118402283\n",
      "\n",
      "\n",
      "\n",
      "GausianNB\n",
      "=========\n",
      "Training Accuracy: 0.8859\n",
      "Training Error Rate: 0.1141\n",
      "Training F1 Score: 0.8954\n",
      "Training Confusion Matrix:\n",
      "[[64154  5967]\n",
      " [ 2808  3973]]\n",
      "Training sensitivity:  0.5859017843975814\n",
      "Training specificity:  0.9149042369618231\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8817\n",
      "Test Error Rate: 0.1183\n",
      "Test F1 Score: 0.8920\n",
      "Test Confusion Matrix:\n",
      "[[15963  1562]\n",
      " [  713   988]]\n",
      "Test sensitivity:  0.5808348030570253\n",
      "Test specificity:  0.910870185449358\n",
      "\n",
      "\n",
      "\n",
      "XGBoost\n",
      "=======\n",
      "Training Accuracy: 0.9761\n",
      "Training Error Rate: 0.0239\n",
      "Training F1 Score: 0.9745\n",
      "Training Confusion Matrix:\n",
      "[[70088    33]\n",
      " [ 1804  4977]]\n",
      "Training sensitivity:  0.7339625423978764\n",
      "Training specificity:  0.9995293849203519\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9687\n",
      "Test Error Rate: 0.0313\n",
      "Test F1 Score: 0.9663\n",
      "Test Confusion Matrix:\n",
      "[[17472    53]\n",
      " [  548  1153]]\n",
      "Test sensitivity:  0.6778365667254557\n",
      "Test specificity:  0.9969757489300999\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define your categorical and numeric columns\n",
    "categorical_cols = ['gender', 'hypertension', 'heart_disease', 'smoking_history_current', 'smoking_history_non-smoker', 'smoking_history_past_smoker']\n",
    "numeric_cols = ['age', 'blood_glucose_level','HbA1c_level', 'bmi']\n",
    "\n",
    "# ... (load your train and test data)\n",
    "\n",
    "models = {\n",
    "    'Multiple Logistic': LogisticRegression(solver='liblinear'),\n",
    "    'Ridge': LogisticRegression(penalty='l2', C=1.0),\n",
    "    'Lasso': LogisticRegression(penalty='l1', C=1, solver='liblinear'),\n",
    "    'Elastic-net':LogisticRegression(penalty='elasticnet', l1_ratio=0.5, C=1, solver='saga'),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'GausianNB': GaussianNB(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "# Create an OneHotEncoder instance\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Fit and transform the encoder on your categorical columns\n",
    "train_cat_encoded = encoder.fit_transform(train_feature[categorical_cols])\n",
    "test_cat_encoded = encoder.transform(test_feature[categorical_cols])\n",
    "\n",
    "# Concatenate the encoded categorical features with the numeric features\n",
    "train_encoded = np.concatenate((train_cat_encoded, train_feature[numeric_cols]), axis=1)\n",
    "test_encoded = np.concatenate((test_cat_encoded, test_feature[numeric_cols]), axis=1)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    print('=' * len(name))\n",
    "\n",
    "    if name == 'Random Forest':\n",
    "        param_grid = {\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'n_estimators': [50, 100, 200]\n",
    "        }\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(train_encoded, train_label)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        model = best_model\n",
    "\n",
    "    # Fit the model on the encoded data\n",
    "    model.fit(train_encoded, train_label)\n",
    "    \n",
    "     # Training set\n",
    "    train_pred = model.predict(train_encoded)\n",
    "    train_acc = accuracy_score(train_label, train_pred)\n",
    "    train_err = 1 - train_acc\n",
    "    train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "    train_cm = confusion_matrix(train_label, train_pred)\n",
    "    train_sensitivity = train_cm[1, 1] / (train_cm[1, 1] + train_cm[1, 0])\n",
    "    train_specificity = train_cm[0, 0] / (train_cm[0, 0] + train_cm[0, 1])\n",
    "\n",
    "    # Test set\n",
    "    test_pred = model.predict(test_encoded)\n",
    "    test_acc = accuracy_score(test_label, test_pred)\n",
    "    test_err = 1 - test_acc\n",
    "    test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "    test_cm = confusion_matrix(test_label, test_pred)\n",
    "    test_sensitivity = test_cm[1, 1] / (test_cm[1, 1] + test_cm[1, 0])\n",
    "    test_specificity = test_cm[0, 0] / (test_cm[0, 0] + test_cm[0, 1])\n",
    "\n",
    "    print(f'Training Accuracy: {train_acc:.4f}')\n",
    "    print(f'Training Error Rate: {train_err:.4f}')\n",
    "    print(f'Training F1 Score: {train_f1:.4f}')\n",
    "    print(f'Training Confusion Matrix:\\n{train_cm}')\n",
    "    print(\"Training sensitivity: \", train_sensitivity)\n",
    "    print(\"Training specificity: \", train_specificity)\n",
    "    print('\\n')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test Error Rate: {test_err:.4f}')\n",
    "    print(f'Test F1 Score: {test_f1:.4f}')\n",
    "    print(f'Test Confusion Matrix:\\n{test_cm}')\n",
    "    print(\"Test sensitivity: \", test_sensitivity)\n",
    "    print(\"Test specificity: \", test_specificity)\n",
    "\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ecd17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a2574",
   "metadata": {},
   "source": [
    "# ensemble technique - stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b775d",
   "metadata": {},
   "source": [
    "1. Stacking: It is an ensemble method that combines multiple models (classification or regression) via meta-model (meta-classifier or meta-regression). The base models are trained on the complete dataset, then the meta-model is trained on features returned (as output) from base models. The base models in stacking are typically different. The meta-model helps to find the features from base models to achieve the best accuracy.\n",
    "    \n",
    "    Stacking is a bit different from the basic ensembling methods because it has first-level and second-level models. Stacking features are first extracted by training the dataset with all the first-level models. A first-level model is then using the train stacking features to train the model than this model predicts the final output with test stacking features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a59fe6",
   "metadata": {},
   "source": [
    "Algorithm:\n",
    "\n",
    "        Split the train dataset into n parts\n",
    "        A base model (say linear regression) is fitted on n-1 parts and predictions are made for the nth part. This is done for each one of the n part of the train set.\n",
    "        The base model is then fitted on the whole train dataset.\n",
    "        This model is used to predict the test dataset.\n",
    "        The Steps 2 to 4 are repeated for another base model which results in another set of predictions for the train and test dataset.\n",
    "        The predictions on train data set are used as a feature to build the new model.\n",
    "        This final model is used to make the predictions on test dataset\n",
    "        \n",
    "https://www.geeksforgeeks.org/ensemble-methods-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63c820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [XGBClassifier]\n",
      "    fold  0:  [0.97249854]\n",
      "    fold  1:  [0.97165334]\n",
      "    fold  2:  [0.96911573]\n",
      "    fold  3:  [0.97243173]\n",
      "    fold  4:  [0.97204161]\n",
      "    ----\n",
      "    MEAN:     [0.97154819] + [0.00125341]\n",
      "    FULL:     [0.97154820]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.96957285]\n",
      "    fold  1:  [0.96879267]\n",
      "    fold  2:  [0.96657997]\n",
      "    fold  3:  [0.97041612]\n",
      "    fold  4:  [0.96905072]\n",
      "    ----\n",
      "    MEAN:     [0.96888247] + [0.00127801]\n",
      "    FULL:     [0.96888247]\n",
      "\n",
      "model  2:     [LogisticRegression]\n",
      "    fold  0:  [0.96053573]\n",
      "    fold  1:  [0.96001560]\n",
      "    fold  2:  [0.95715215]\n",
      "    fold  3:  [0.95864759]\n",
      "    fold  4:  [0.95994798]\n",
      "    ----\n",
      "    MEAN:     [0.95925981] + [0.00122391]\n",
      "    FULL:     [0.95925984]\n",
      "\n",
      "Ensemble Train Accuracy: 0.9712361186965228\n",
      "Ensemble Test Accuracy: 0.9691563507749922\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vecstack import stacking\n",
    "\n",
    "\n",
    "# Train XGBoost and Random Forest models\n",
    "xgb_model = XGBClassifier(learning_rate= 0.1, max_depth = 3, n_estimators = 200)\n",
    "rf_model = RandomForestClassifier()\n",
    "lr_model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Create a stacking model with a meta-model (Logistic Regression)\n",
    "models = [xgb_model, rf_model, lr_model]\n",
    "meta_model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Perform stacking to generate ensemble predictions\n",
    "S_train, S_test = stacking(models, train_encoded, train_label, test_encoded,\n",
    "                           regression=False, metric=accuracy_score,\n",
    "                           n_folds=5, shuffle=True, random_state=42,\n",
    "                           verbose=2)\n",
    "\n",
    "# Train the meta-model on the stacked predictions\n",
    "meta_model.fit(S_train, train_label)\n",
    "\n",
    "# Ensemble predictions using the meta-model\n",
    "ensemble_train_preds = meta_model.predict(S_train)\n",
    "ensemble_test_preds = meta_model.predict(S_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "ensemble_train_acc = accuracy_score(train_label, ensemble_train_preds)\n",
    "ensemble_test_acc = accuracy_score(test_label, ensemble_test_preds)\n",
    "\n",
    "print(\"Ensemble Train Accuracy:\", ensemble_train_acc)\n",
    "print(\"Ensemble Test Accuracy:\", ensemble_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89af640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [XGBClassifier]\n",
      "    fold  0:  [0.97048306]\n",
      "    fold  1:  [0.97048306]\n",
      "    fold  2:  [0.96827048]\n",
      "    fold  3:  [0.97145644]\n",
      "    fold  4:  [0.97015605]\n",
      "    ----\n",
      "    MEAN:     [0.97016982] + [0.00104492]\n",
      "    FULL:     [0.97016983]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.96957285]\n",
      "    fold  1:  [0.96762239]\n",
      "    fold  2:  [0.96618986]\n",
      "    fold  3:  [0.97080624]\n",
      "    fold  4:  [0.96846554]\n",
      "    ----\n",
      "    MEAN:     [0.96853138] + [0.00158575]\n",
      "    FULL:     [0.96853138]\n",
      "\n",
      "model  2:     [LogisticRegression]\n",
      "    fold  0:  [0.95351408]\n",
      "    fold  1:  [0.95364411]\n",
      "    fold  2:  [0.95539662]\n",
      "    fold  3:  [0.95682705]\n",
      "    fold  4:  [0.95942783]\n",
      "    ----\n",
      "    MEAN:     [0.95576194] + [0.00220203]\n",
      "    FULL:     [0.95576188]\n",
      "\n",
      "Ensemble Train Accuracy: 0.9704559049179475\n",
      "Ensemble Test Accuracy: 0.9685842088838031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vecstack import stacking\n",
    "\n",
    "\n",
    "# Train XGBoost and Random Forest models\n",
    "xgb_model = XGBClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Create a stacking model with a meta-model (Logistic Regression)\n",
    "models = [xgb_model, rf_model, lr_model]\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Perform stacking to generate ensemble predictions\n",
    "S_train, S_test = stacking(models, train_encoded, train_label, test_encoded,\n",
    "                           regression=False, metric=accuracy_score,\n",
    "                           n_folds=5, shuffle=True, random_state=42,\n",
    "                           verbose=2)\n",
    "\n",
    "# Train the meta-model on the stacked predictions\n",
    "meta_model.fit(S_train, train_label)\n",
    "\n",
    "# Ensemble predictions using the meta-model\n",
    "ensemble_train_preds = meta_model.predict(S_train)\n",
    "ensemble_test_preds = meta_model.predict(S_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "ensemble_train_acc = accuracy_score(train_label, ensemble_train_preds)\n",
    "ensemble_test_acc = accuracy_score(test_label, ensemble_test_preds)\n",
    "\n",
    "print(\"Ensemble Train Accuracy:\", ensemble_train_acc)\n",
    "print(\"Ensemble Test Accuracy:\", ensemble_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db62d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [XGBClassifier]\n",
      "    fold  0:  [0.97048306]\n",
      "    fold  1:  [0.97048306]\n",
      "    fold  2:  [0.96827048]\n",
      "    fold  3:  [0.97145644]\n",
      "    fold  4:  [0.97015605]\n",
      "    ----\n",
      "    MEAN:     [0.97016982] + [0.00104492]\n",
      "    FULL:     [0.97016983]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.96957285]\n",
      "    fold  1:  [0.96827254]\n",
      "    fold  2:  [0.96579974]\n",
      "    fold  3:  [0.97041612]\n",
      "    fold  4:  [0.96963589]\n",
      "    ----\n",
      "    MEAN:     [0.96873943] + [0.00162292]\n",
      "    FULL:     [0.96873943]\n",
      "\n",
      "model  2:     [LogisticRegression]\n",
      "    fold  0:  [0.96060074]\n",
      "    fold  1:  [0.96008062]\n",
      "    fold  2:  [0.95747724]\n",
      "    fold  3:  [0.95845254]\n",
      "    fold  4:  [0.95988296]\n",
      "    ----\n",
      "    MEAN:     [0.95929882] + [0.00115601]\n",
      "    FULL:     [0.95929885]\n",
      "\n",
      "Ensemble Train Accuracy: 0.9707419833034251\n",
      "Ensemble Test Accuracy: 0.9688442733797982\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vecstack import stacking\n",
    "\n",
    "\n",
    "# Train XGBoost and Random Forest models\n",
    "xgb_model = XGBClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "llr_model = LogisticRegression(penalty='l1', C=1, solver='liblinear')\n",
    "\n",
    "# Create a stacking model with a meta-model (Logistic Regression)\n",
    "models = [xgb_model, rf_model, llr_model]\n",
    "meta_model = LogisticRegression(penalty='l1', C=1, solver='liblinear')\n",
    "\n",
    "# Perform stacking to generate ensemble predictions\n",
    "S_train, S_test = stacking(models, train_encoded, train_label, test_encoded,\n",
    "                           regression=False, metric=accuracy_score,\n",
    "                           n_folds=5, shuffle=True, random_state=42,\n",
    "                           verbose=2)\n",
    "\n",
    "# Train the meta-model on the stacked predictions\n",
    "meta_model.fit(S_train, train_label)\n",
    "\n",
    "# Ensemble predictions using the meta-model\n",
    "ensemble_train_preds = meta_model.predict(S_train)\n",
    "ensemble_test_preds = meta_model.predict(S_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "ensemble_train_acc = accuracy_score(train_label, ensemble_train_preds)\n",
    "ensemble_test_acc = accuracy_score(test_label, ensemble_test_preds)\n",
    "\n",
    "print(\"Ensemble Train Accuracy:\", ensemble_train_acc)\n",
    "print(\"Ensemble Test Accuracy:\", ensemble_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdfa45e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002118777257753446"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9712231151335466-0.9691043378757932 #xgb with hyperpara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c4771e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002118778610459393"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9712751293854516- 0.9691563507749922 ##log(solver='liblinear') + #xgb with hyperpara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "992c8e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0020537445631059192"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9705859405477101-0.9685321959846042 #none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bd15308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018977072182149168"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9706379547996151-0.9687402475814002 #log(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1917b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
